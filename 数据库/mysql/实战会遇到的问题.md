## 锁

[锁问题排查](https://www.yijiyong.com/mysqlop/monitorlock/02-lockdealcase.html)



## 尽量不要使用长事务

1. 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留（**从事务开始到现在为止所有的更新记录都要先保留，事务回滚需要一条条的回滚回去**），这就会导致大量占用存储空间。
2. 长事务会一直占用锁，直到事务结束，会影响其他事务的执行。



## MySQL为什么有时候会选错索引（10）

选择索引是优化器的工作。
	而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。

考虑行数、回表的消耗，以及是否排序。

解决：

采用force index强行选择一个索引（不优雅）

我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。



## 为什么我的MySQL会“抖”一下？（12）

​	平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。

​	InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。

​	MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。在InnoDB中，`innodb_flush_neighbors`参数为值为1的时候会有上述的**“连坐”机制**，值为0时表示不找邻居，自己刷自己的。



##### 什么时候会刷脏页

1. 是InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。
2. 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。（LRU算法）
3. 系统空闲时
4. mysql正常关闭时，会把内存所有的脏页都刷到磁盘上。

##### InnoDB刷脏页的控制策略

​	`innodb_io_capacity`这个参数会告诉InnoDB你的磁盘能力建议你设置成磁盘的IOPS，磁盘的IOPS可以通过fio这个工具来测试。

​	InnoDB的刷盘速度要参考这两个因素：一个是脏页比例，一个是redo log写盘速度。InnoDB会根据这两个因素先单独算出两个数字，取较大值R，之后引擎就可以按照`innodb_io_capacity`定义的能力乘以R%来控制刷脏页的速度。

## 为什么表数据删掉一半，表文件大小不变？（13）

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数`innodb_file_per_table`控制的：

1. 这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
2. 这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。(而*frm文件*是innodb的表结构文件)



​	将innodb_file_per_table设置为ON，是推荐做法。通过drop table命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

​	delete命令只是把记录的位置或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。**不止是删除数据会造成空洞，插入数据也会。**

​	如果要收缩一个表，只是delete掉表里面不用的数据的话(**产生空洞**)，表文件的大小是不会变的，你还要**通过alter table命令重建表，才能达到表文件变小的目的**。使用`alter table A engine=InnoDB`命令来重建表，这个命令在MySQL 5.6版本是Online DDL（生成临时文件的时候会记录期间的修改操作），Online DDL的方式是可以考虑在业务低峰期使用的，而MySQL 5.5及之前的版本，这个命令是会阻塞DML的，这个你需要特别小心。

​	上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗IO和CPU资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用GitHub开源的gh-ost来做。

## 不要对索引字段做函数操作（18）

​	对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。如果对索引的值做函数操作并不会破坏索引的有序性，影响查找速度。



## 短期影响性能的方式（22）

#### 短连接暴增

1. 先处理掉那些占着连接但是不工作的线程（优先断开像事务外空闲的连接，通过information_schema.innodb_trx判断是否在事务中）
2. 减少连接过程的消耗（是让数据库跳过权限验证阶段，**不建议，安全性很低**）

#### 慢查询性能问题

​	常见原因有：

1. 索引没有设计好；
2. SQL语句没写好；
3. MySQL选错了索引。

​	

​	对应的解决方案：

 	1. MySQL 5.6版本以后，创建索引都支持Online DDL了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行alter table 语句。
 	2. MySQL 5.7提供了query_rewrite功能，可以把输入的一种语句改写成另外一种模式。
 	3. 应急方案就是给这个语句加上force index。

#### QPS突增问题

​	有时候由于业务突然出现高峰，或者应用程序bug，导致某个语句的QPS突然暴涨，也可能导致
MySQL压力过大，影响服务。

​	解决办法：去掉权限验证，阻止业务查询。



## 如何恢复误删数据（31）

#### 误删行

​	可以用Flashback工具通过闪回把数据恢复回来。Flashback恢复数据的原理是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保`binlog_format=row`和 `binlog_row_image=FULL`。

具体恢复数据时，对单个事务做如下处理：
1. 对于insert语句，对应的binlog event类型是`Write_rows event`，把它改成`Delete_rows even`t即可；
2. 同理，对于delete语句，也是将`Delete_rows event`改为`Write_rows event`；
3. 而如果是Update_rows的话，binlog里面记录了数据行修改前和修改后的值，对调这两行的位置即可。




​	把`sql_safe_updates`参数设置为on。这样一来，如果我们忘记在delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错。

​	

#### 误删库/表

​	delete全表是很慢的，需要生成回滚日志、写redo、写binlog。**从性能角度考虑，应该优先考虑使用truncate table或者drop table命令。**

​	使用delete命令删除的数据，你还可以用Flashback来恢复。**而使用truncate /drop table和drop database命令删除的数据，就没办法通过Flashback来恢复了。**因为即使我们配置了`binlog_format=row`，执行这三个命令时，记录的binlog还是statement格式。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的。

​	这种情况下，**要想恢复数据，就需要使用全量备份，加增量日志的方式了**。这个方案要求线上有
定期的全量备份，并且实时备份binlog。

##### 加快备份速度

​	如果这个临时库上有多个数据库，你可以在使用mysqlbinlog命令时，加上一个–database参数，用来指定误删表所在的库。



还不够快：

1. 如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是mysqlbinlog工具并不能指定只解析一个表的日志；
2. . 用mysqlbinlog解析出日志应用，应用日志的过程就只能是**单线程**。备库并行应用binlog方式在这里无法使用。



一种加速的方法是，**在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库**，
这样：

1. 在start slave之前，先通过执行`change replication filter replicate_do_table = (tbl_name)` 命令，就可以让临时库只同步误操作的表；
2. 这样做也可以用上并行复制技术，来加速整个数据恢复过程。



​	通过搭建延迟复制的备库，延迟复制的备库是一种特殊的备库，通过` CHANGE MASTER TOMASTER_DELAY =N`命令，可以指定这个备库持续保持跟主库有N秒的延迟。比如你把N设置为3600，这就代表了如果主库上有数据被误删了，并且在1小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行`stop slave`，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。（**故意设置主备延迟，在这段时间发现，删除命令还没有执行，通过设置GTID来跳过。**）



## kill命令语意（32）

​	在MySQL中有两个kill命令：一个是`kill query+线程id`，表示终止这个线程中正在执行的语句；一个是`kill connection +线程id`，这里connection可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。**kill query并不会终止连接，而是单纯的停止当前执行的 语句。	**

#### kill query

实现上，当用户执行kill query thread_id_B时，MySQL里处理kill命令的线程做了两件事：

1. 把session B的运行状态改成THD::KILL_QUERY(将变量killed赋值为`THD::KILL_QUERY`)；
2. 给session B的执行线程发一个信号。**发一个信号的目的，就是让session B退出等待，来处理这个THD::KILL_QUERY状态。**

#### kill connection

执行kill connection 命令时，是这么做的，
1. 把线程状态设置为KILL_CONNECTION；
2. 关掉号线程的网络连接。因为有这个操作，事务收到了断开连接的提示。



#### 无法kill

1. 线程没有执行到判断线程状态的逻辑。
2. 终止逻辑耗时较长,从`show processlist`结果上看也是`Command=Killed`，需要等到终止逻辑完成，语句才算真正完成。



第一种情况

1. mysql当前设定的并发线程都被占用了，导致没有进入终止逻辑。
2. 由于IO压力过大，读写IO的函数一直无法返回，导致不能及时判断线程的状态。



其中第二点常见的情况有：

1. 超大事务执行期间被kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回
收操作，耗时很长。
2. 大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临
时文件可能需要等待IO资源，导致耗时较长。
3. DDL命令执行到最后阶段，如果被kill，需要删除中间过程的临时文件，也可能受IO资源影响
耗时较久。



#### 总结

​	这些“kill不掉”的情况，其实是因为发送kill命令的客户端，并没有强行停止目标线程的执行，而**只**
**是设置了个状态，并唤醒对应的线程**。而被kill的线程，需要执行到判断状态的“埋点”，才会开始
进入终止逻辑阶段。并且，**终止逻辑本身也是需要耗费时间的**。





## 全表数据查询

### 全表扫描对server层的影响

全表数据扫描服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：

1. 获取一行，写到net_buffer中。这块内存的大小是由参数net_buffer_length定义的，默认是16k。
2. 重复获取行，直到net_buffer写满，调用网络接口发出去。
3. 如果发送成功，就清空net_buffer，然后继续取下一行，并写入net_buffer。
4. 如果发送函数返回EAGAIN或WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。



​	由于MySQL采用的是边读边发的逻辑，因此对于数据量很大的查询结果来说，不会在server端保存完整的结果集。**如果客户端读结果不及时，会堵住MySQL的查询过程，但是不会把内存打爆**。

​	仅当一个线程处于“等待客户端接收结果”的状态，才会显示"Sending to client"；而如果显示成“Sending data”，它的意思只是“正在执行”。

![1679662750311](C:\Users\Chenhui\AppData\Roaming\Typora\typora-user-images\1679662750311.png)



### 全表扫描对InnoDB的影响

​	内存的数据页是在Buffer Pool (BP)中管理的，在WAL里Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。而Buffer Pool对查询的加速效果，依赖于一个重要的指标，即：**内存命中率**。执行`showengine innodb status `，可以看到“Buffer pool hit rate”字样，显示的就是当前的命中率。

​	而对于InnoDB引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。并且，**由于InnoDB对LRU算法做了改进，冷数据的全表扫描，对Buffer Pool的影响也能做到可控。**



## 自增主键不连续

​	在MyISAM引擎里面，自增值是被**写在数据文件上**的。而在InnoDB中，自增值是被**记录在内存**的。MySQL直到8.0版本，才给InnoDB表的自增值加上了持久化的能力，确保重启前后一个表的自增值不变。

### 自增值修改机制

如果字段id被定义为AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：
1. 如果插入数据时id字段指定为0、null 或未指定值，那么就把这个表当前的AUTO_INCREMENT值填到自增字段；
2. 如果插入数据时id字段指定了具体的值，就直接使用语句里指定的值。



某次要插入的值是X，当前的自增值是Y。

1. 如果X<Y，那么这个表的自增值不变；

2. 如果X>=Y，就需要把当前自增值修改为新的自增值。

   新的自增值生成算法是：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于X的值，作为新的自增值。



​	自增id锁并**不是一个事务锁，而是每次申请完就马上释放**，以便允许别的事务再申请。新增参数`innodb_autoinc_lock_mode`，默认值是1。

1. 这个参数的值被设置为0时，表示采用之前MySQL 5.0版本的策略，即语句执行结束后才释放锁；
2. 这个参数的值被设置为1时：
- 普通insert语句，自增锁在申请之后就马上释放；
- 类似insert …select这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
3. 这个参数的值被设置为2时，所有的申请自增主键的动作都是申请后就释放锁。



### 出现不连续的情况

由于自增主键不会回滚

1. 唯一键冲突是导致自增主键id不连续
2. 事务回滚
3. 批量插入数据的语句，是分多次申请自增id的。每次都是上次的2倍，最后一次申请的自增id可能存在浪费。



## 主备切换（25）

#### 主备延迟大的原因

1. 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。
2. 备库的压力大。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。
3. 大事务。主库上必须等事务执行完成才会写入binlog，再传给备库。如果一个主库上的语句执行10分钟，那这个事务很可能就会导致从库延迟10分钟。**不要一次性地用delete语句删除太多数据。其**
   **实，这就是一个典型的大事务场景。**
4. 备库的并行复制能力



#### 切换策略

1. 可靠性优先策略，切换过程中有不可用时间，不能写。
2. 可用性优先策略，先把备库可写状态，然后切换。这样子的后果就是可能会出现数据不一致。



### 一主多从的切换

​	相比于一主一备的切换流程，一主多从结构在切换完成后，A’会成为新的主库，从库B、C、D也要改接到A’。正是由于多了从库B、C、D重新指向的这个过程，所以主备切换的复杂性也相应增加了。
​						![1679671082253](C:\Users\Chenhui\AppData\Roaming\Typora\typora-user-images\1679671082253.png)

#### 基于位点的主备切换

​	当我们把节点B设置成节点A’的从库的时候，需要执行一条change master命令：

```mysql
CHANGE MASTER TO
MASTER_HOST=$host_name
MASTER_PORT=$port
MASTER_USER=$user_name
MASTER_PASSWORD=$password
MASTER_LOG_FILE=$master_log_name
MASTER_LOG_POS=$master_log_pos
```

​	最后两个参数`MASTER_LOG_FILE`和`MASTER_LOG_POS`表示，要从主库的master_log_name文件的master_log_pos这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。

​	原来节点B是A的从库，本地记录的也是A的位点。但是相同的日志，A的位点和A’的位点是不同的。因此，从库B要切换的时候，就需要先经过“找同步位点”这个逻辑。**这个位点很难精确取到，只能取一个大概位置。**

​	考虑到切换过程中不能丢数据，所以找位点的时候，**总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务**。

一种取同步位点的方法是这样的：

1. 等待新主库A’把中转日志（relay log）全部同步完成；
2. 在A’上执行showmaster status命令，得到当前A’上最新的File 和 Position；
3. 取原主库A故障的时刻T；
4. 用mysqlbinlog工具解析A’的File，得到T时刻的位点。



#### 基于GTID的主备切换

##### GTID

​	每个MySQL实例都维护了一个GTID集合，用来对应“这个实例执行过的所有事务”。

​	GTID模式的启动也很简单，我们只需要在启动一个MySQL实例的时候，加上参数gtid_mode=on
和enforce_gtid_consistency=on就可以了。

​	在GTID模式下，每个事务都会跟一个GTID一一对应。这个GTID有两种生成方式，而使用哪种
方式取决于session变量gtid_next的值。

1. 如果gtid_next=automatic，代表使用默认值。这时，MySQL就会把server_uuid:gno分配给
   GTID=server_uuid:gno这个事务。
   a. 记录binlog的时候，先记录一行 SET@@SESSION.GTID_NEXT=‘server_uuid:gno’;
   b. 把这个GTID加入本实例的GTID集合。
2. 如果gtid_next是一个指定的GTID的值，比如通过set gtid_next='current_gtid’指定为current_gtid，那么就有两种可能：
   a. **如果current_gtid已经存在于实例的GTID集合中，接下来执行的这个事务会直接被系统忽略；（非常有用的特性，可能用来规避主库传来的引起冲突的binlog）**
   b. 如果current_gtid没有存在于实例的GTID集合中，就将这个current_gtid分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的GTID，因此gno也不用加1。



​	如果实例有从库，那么将CREATE TABLE和insert语句的binlog同步过去执行的话，执行事务之前就会先执行这两个SET命令， 这样被加入从库的GTID集合的，就是图中的这两个GTID。

![1679672229536](C:\Users\Chenhui\AppData\Roaming\Typora\typora-user-images\1679672229536.png)



##### 主备切换过程

​	在GTID模式下，备库B要设置为新主库A’的从库的语法如下：

```mysql
CHANGE MASTER TO
MASTER_HOST=$host_name
MASTER_PORT=$port
MASTER_USER=$user_name
MASTER_PASSWORD=$password
master_auto_position=1
```

​	其中，master_auto_position=1就表示这个主备关系使用的是GTID协议。可以看到，前面让我们头疼不已的`MASTER_LOG_FILE`和`MASTER_LOG_POS`参数，已经不需要指定了。

我们在实例B上执行start slave命令，取binlog的逻辑是这样的：

	1. 实例B指定主库A’，基于主备协议建立连接。
 	2. 实例B把set_b发给主库A’。
 	3. 实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。
     a. **如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误**；
     b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；
 	4. 之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。



​	在基于GTID的主备关系里，系统认为只要建立主备关系，就**必须保证主库发给备库的日志是完整的。**因此，如果实例B需要的日志已经不存在，A’就拒绝把日志发给B。

##### 切换前后的GTID格式

​	这个系统就由新主库A’写入，主库A’的自己生成的binlog中的GTID集合格式是：server_uuid_of_A’:1-M。如果之前从库B的GTID集合格式是 server_uuid_of_A:1-N， 那么切换之后GTID集合的格式就变成了server_uuid_of_A:1-N, server_uuid_of_A’:1-M。
​	当然，**主库A’之前也是A的备库，因此主库A’和从库B的GTID集合是一样的（server_uuid_of_A:1-N）**。这就达到了我们预期。



## 读写分离的坑（28）

​	由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。**这种“在从库上会读到系统的一个过期状态”的现象，称之为“过期读”。**	

​	如果不允许过期读的要求，就只有两种选择，一种是超时放弃，一种是转到主库。**此时处理过期读的主要思想就是对于当前查询根据一定条件判断从库是否支持最近的数据，支持就走从库。不支持再走主库。**

处理过期读的方案有：

> 强制走主库方案；
> sleep方案；
> 判断主备无延迟方案；
> 配合semi-sync方案；
> 等主库位点方案；
> 等GTID方案。

判断主备无延迟方案

1. seconds_behind_master是否已经等于0。如果还不等于0 ，那就必须等到这个参数变为0才能执行查询请求。
2. 通过位点或者GTID判断备库收到的日志都执行完成了。



等主库位点方案和等GTID方案（判断主库这个事务是否已经在备库执行了），具体如下：

再执行一个查询请求的逻辑，要保证能够查到正确的数据，我们可以使用这个逻辑：

1. trx1事务更新完成后，马上执行showmaster status得到当前主库执行到的File和Position；
2. 选定一个从库执行查询语句；
3. 在从库上执行select master_pos_wait(File, Position, 1)；
4. 如果返回值是>=0的正整数，则在这个从库执行查询语句；
5. 否则，到主库执行查询语句。



## 问题

1.我在事务1中执行 `begin;select * from t where c=5 for update;`（**c是索引**）事务未提交，然后事务2中`begin; update t set c=5 where id=0;`执行阻塞，替换成`update t set c=11 where id=0;`执行不阻塞，我觉得原因是事务1执行时产生next-key lock范围是(0,5].(5,10]。我想问下update set操作c=xxx是会加锁吗？以及加锁的原理。
2.一直以为gap只会在二级索引上，看了你的死锁案例，发现主键索引上也会有gap锁？

1. 好问题。你可以理解为要在索引c上插入一个(c=5,id=0)这一行，是落在(0,5],(5,10]里面的，11可以对吧
2. 嗯，主键索引的间隙上也要有Gap lock保护的



从结果来看，间隙锁是加载for update的字段上也就是上述问题的c=5上。后面如果尝试在c=5两边的间隙上插入数据或者修改c=5这行都会锁住。





##### 为什么binlog cache是每个线程自己维护的，而redo log buffer是全局共用的？

回答：MySQL这么设计的主要原因是，binlog是不能“被打断的”。一个事务的binlog必须连续
写，因此要整个事务完成后，再一起写到文件里。
而redo log并没有这个要求，中间有生成的日志可以写到redo log buffer中。redo log buffer中的
内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。